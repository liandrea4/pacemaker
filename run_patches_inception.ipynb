{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from bs4                     import BeautifulSoup\n",
    "import matplotlib.pyplot     as plt\n",
    "import matplotlib.image      as mpimg\n",
    "import numpy                 as np\n",
    "import skimage.transform\n",
    "import dicom\n",
    "import glob\n",
    "import model\n",
    "import scipy.misc\n",
    "import os\n",
    "import h5py\n",
    "import json\n",
    "import pylab\n",
    "\n",
    "data_filepath = \"/enc_data/eddata/pacemaker/\"\n",
    "ann_filepath = data_filepath + \"ann/\"\n",
    "img_filepath = data_filepath + 'organized-data/'\n",
    "png_filepath = data_filepath + 'png/'\n",
    "\n",
    "SIZE_X = 726\n",
    "SIZE_Y = 726\n",
    "VGG_DIMS = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    def resize(image):\n",
    "        \"\"\" Resizes the image into dimensions specified by dims and converts img to 3 channels \"\"\"\n",
    "        newimg = skimage.transform.resize(image, VGG_DIMS)\n",
    "\n",
    "        # Convert from 1 channel to 3 channels\n",
    "        newimg_3d = np.empty(VGG_DIMS + (3,))\n",
    "        for i in range(3):\n",
    "            newimg_3d[:,:,i] = newimg\n",
    "\n",
    "        return newimg_3d\n",
    "\n",
    "    def load_images(path, number):\n",
    "        \"\"\" Path: Path to .png images\n",
    "            Number: Number of images to run\n",
    "            Dims: (height, width) of the final images that will be fed into the model \"\"\"\n",
    "\n",
    "        return np.array([ resize(plt.imread(path + image_path)) for image_path in os.listdir(path)[:number] ])\n",
    "    \n",
    "    pos_imgs = load_images(png_filepath + \"pacemaker/max_size/\", number=300)\n",
    "    neg_imgs = load_images(png_filepath + \"neg/\", number=300)\n",
    "    \n",
    "    X = np.concatenate((pos_imgs, neg_imgs))\n",
    "    Y = np.array([1] * pos_imgs.shape[0] + [0] * neg_imgs.shape[0])\n",
    "    print X.shape, Y.shape\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 224, 224, 3) (600,)\n"
     ]
    }
   ],
   "source": [
    "X, Y = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from sklearn.model_selection         import train_test_split\n",
    "from keras.applications.vgg16        import VGG16\n",
    "from keras.applications.inception_v3        import InceptionV3\n",
    "\n",
    "\n",
    "from keras.preprocessing.image       import ImageDataGenerator\n",
    "from keras.models                    import Sequential, Model, Input\n",
    "from keras.layers                    import Dense, Flatten, Dropout\n",
    "from keras.optimizers                import SGD, RMSprop, Adam\n",
    "from keras.callbacks                 import EarlyStopping\n",
    "from keras.utils                     import np_utils\n",
    "from keras                           import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train shape: ', (360, 224, 224, 3), (360,))\n",
      "('Val shape: ', (120, 224, 224, 3), (120,))\n",
      "('Test shape: ', (120, 224, 224, 3), (120,))\n"
     ]
    }
   ],
   "source": [
    "# Split into test and train/validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.6, random_state=42, stratify=Y)\n",
    "\n",
    "# Split into train and validation\n",
    "X_test, X_val, y_test, y_val= train_test_split(X_test, y_test, train_size=0.5, random_state=42, stratify=y_test) \n",
    "print('Train shape: ', X_train.shape, y_train.shape)\n",
    "print('Val shape: ', X_val.shape, y_val.shape)\n",
    "print('Test shape: ', X_test.shape, np.array(y_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('y_train, y_val, y_test: ', (360, 2), (120, 2), (120, 2))\n"
     ]
    }
   ],
   "source": [
    "# Categorize the labels\n",
    "num_classes = 2\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_val = np_utils.to_categorical(y_val, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "print(\"y_train, y_val, y_test: \", y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base pre-trained model\n",
    "base_model = InceptionV3(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "# k = 1 # number of end layers to retrain\n",
    "# layers = base_model.layers[:-k] if k != 0 else base_model.layers\n",
    "# for layer in layers: \n",
    "#     layer.trainable = False\n",
    "# #print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "360/360 [==============================] - 9s 24ms/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 2/10\n",
      "360/360 [==============================] - 2s 7ms/step - loss: 0.0098 - acc: 0.9972\n",
      "Epoch 3/10\n",
      "360/360 [==============================] - 2s 7ms/step - loss: 0.0186 - acc: 0.9944\n",
      "Epoch 4/10\n",
      "360/360 [==============================] - 2s 7ms/step - loss: 0.0119 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "360/360 [==============================] - 2s 7ms/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "360/360 [==============================] - 2s 7ms/step - loss: 0.0107 - acc: 0.9972\n",
      "Epoch 7/10\n",
      "360/360 [==============================] - 2s 7ms/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "360/360 [==============================] - 2s 7ms/step - loss: 0.0075 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "360/360 [==============================] - 2s 7ms/step - loss: 0.0111 - acc: 0.9972\n",
      "Epoch 10/10\n",
      "360/360 [==============================] - 2s 7ms/step - loss: 0.0042 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5f4120d990>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = SGD(lr=0.0001, momentum=0.9)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics=[\"accuracy\"])\n",
    "model.fit(x=X_train, y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 2s 21ms/step\n",
      "0.966666666667\n"
     ]
    }
   ],
   "source": [
    "test_loss, accuracy = model.evaluate(x=X_test, y=y_test, verbose=1)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2 (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
