{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dicom\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import glob\n",
    "import re\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dicom.contrib.pydicom_PIL import show_PIL\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# only use GPUID == 1\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image       import ImageDataGenerator\n",
    "from keras.models                    import Sequential, Model, Input\n",
    "from keras.layers                    import Dense, Flatten, Dropout\n",
    "from keras.optimizers                import SGD, RMSprop, Adam\n",
    "from keras.callbacks                 import EarlyStopping\n",
    "from keras.utils                     import np_utils\n",
    "from keras                           import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirPath = '/enc_data/eddata/pacemaker'\n",
    "dataPath = os.path.join(dirPath, 'organized-data')\n",
    "allPatients = os.listdir(dataPath)\n",
    "print('Number of patients: {}'.format(len(allPatients)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pacemakerImgs = set()\n",
    "ratios = []\n",
    "\n",
    "for image_path in glob.glob(os.path.join(dirPath,\"png/full_image/*.png\"))[:number]:\n",
    "    patientid, clipnum = re.split('image\\/(\\d*)_(\\d*)-', image_path)[1:3]\n",
    "    pacemakerImgs.add((patientid, clipnum))\n",
    "    \n",
    "    img = plt.imread(image_path)\n",
    "    ratio = img.shape[1]/float(img.shape[0])\n",
    "    ratios.append(ratio)\n",
    "\n",
    "plt.hist(ratios)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set .85 ratio\n",
    "ratio = .85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale images with current shape to new ratio\n",
    "def getScaledDims(currshape, ratio):\n",
    "    w,h = currshape\n",
    "    currratio = h/float(w)\n",
    "    \n",
    "    if currratio > ratio: # Height is larger\n",
    "        new_h = int(w*ratio)\n",
    "        return (w,new_h)\n",
    "    else:\n",
    "        new_w = int(h/ratio)\n",
    "        return (new_w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.show()\n",
    "print('{} current ratio: {}'.format(img.shape, img.shape[1]/float(img.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdims = getScaledDims(img.shape, ratio)\n",
    "print(newdims, newdims[1]/float(newdims[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropCenter(img,cropy,cropx):\n",
    "    y, x = img.shape\n",
    "    startx = x//2-(cropx//2)\n",
    "    starty = y//2-(cropy//2)    \n",
    "    return img[starty:starty+cropy, startx:startx+cropx, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "croppedimg = cropCenter(img, newdims[0], newdims[1])\n",
    "print(croppedimg.shape, newdims)\n",
    "plt.imshow(croppedimg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImage(image_path, ratio):\n",
    "    img = plt.imread(image_path)\n",
    "    currshape = img.shape\n",
    "    cropy, cropx = getScaledDims(currshape, ratio)\n",
    "    newimg = cropCenter(img,cropy,cropx)\n",
    "    return newimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.85\n",
    "x_True = [loadImage(image_path, ratio) for image_path in glob.glob(os.path.join(dirPath,\"png/full_image/*.png\"))[:number]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most common dimensions and reshape each image to that dimension\n",
    "from scipy.stats import mode\n",
    "\n",
    "shapes = np.array([np.array(img.shape) for img in x_True])\n",
    "imgdims = (mode(shapes[:,0]).mode[0], mode(shapes[:,1]).mode[0])\n",
    "imgdims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgdims + (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Five examples\n",
    "imgdims = (225, 255)\n",
    "\n",
    "for img in x_True[:2]:\n",
    "    print(img.shape)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    newimg = resize(img, imgdims)\n",
    "    newimg_3d = np.empty(imgdims + (3,))\n",
    "    for i in range(3):\n",
    "        newimg_3d[:,:,i] = newimg\n",
    "    print(newimg_3d.shape)\n",
    "    plt.imshow(newimg_3d[:,:,1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate cropped image arrays for each class and resize them to the most common dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "def loadImage(image_path, ratio):\n",
    "    img = plt.imread(image_path)\n",
    "    currshape = img.shape\n",
    "    cropx, cropy = getScaledDims(currshape, ratio)\n",
    "    newimg = cropCenter(img,cropx,cropy)\n",
    "    return newimg\n",
    "\n",
    "def resizeImage(image, dims):\n",
    "    newimg = resize(image, dims)\n",
    "    \n",
    "    # Convert from 1 channel to 3 channels\n",
    "    newimg_3d = np.empty(imgdims + (3,))\n",
    "    for i in range(3):\n",
    "        newimg_3d[:,:,i] = newimg\n",
    "        \n",
    "    return newimg_3d\n",
    "\n",
    "def loadTrueClass(path, number, dims):\n",
    "    \"\"\" Path: Path to .png images\n",
    "        Number: Number of images to run\n",
    "        Dims: (height, width) of the final images that will be fed into the model \"\"\"\n",
    "    \n",
    "    # Crop images to ratio specified.\n",
    "    ratio = dims[1]/float(dims[0])\n",
    "    croppedImgs = [loadImage(image_path, ratio) for image_path in glob.glob(path)[:number]]\n",
    "    \n",
    "    # Resize all images to that dims\n",
    "    x_True = np.array([resizeImage(img, dims) for img in croppedImgs])\n",
    "    return x_True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacemakerPath = os.path.join(dirPath,\"png/full_image/*.png\")\n",
    "x_True = loadTrueClass(pacemakerPath, 50, (225, 255))\n",
    "x_True.shape\n",
    "\n",
    "# Data should match shape format: (samples, height, width, channels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(glob.glob(pacemakerPath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255, horizontal_flip = True, vertical_flip = True)\n",
    "train_datagen.fit(x_True)\n",
    "# generator = train_datagen.flow(X_train, y_train, batch_size=32)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2 (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
