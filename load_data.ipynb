{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dicom\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import glob\n",
    "import re\n",
    "import cPickle as pickle\n",
    "\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dicom.contrib.pydicom_PIL import show_PIL\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "\n",
    "def getScaledDims(currshape, ratio):\n",
    "    \"\"\" Scale images with current shape to new ratio \"\"\"\n",
    "    w,h = currshape\n",
    "    currratio = h/float(w)\n",
    "    \n",
    "    if currratio > ratio: # Height is larger\n",
    "        new_h = int(w*ratio)\n",
    "        return (w,new_h)\n",
    "    else:\n",
    "        new_w = int(h/ratio)\n",
    "        return (new_w, h)\n",
    "\n",
    "def cropCenter(img,cropy,cropx):\n",
    "    \"\"\" Center crop images to new height and new width, specified by cropy, cropx \"\"\"\n",
    "    y, x = img.shape\n",
    "    startx = x//2-(cropx//2)\n",
    "    starty = y//2-(cropy//2)    \n",
    "    return img[starty:starty+cropy, startx:startx+cropx]\n",
    "\n",
    "def loadImage(image_path, ratio):\n",
    "    \"\"\" Returns a np matrix with ratio of dimensions specified by ratio \"\"\"\n",
    "    img = plt.imread(image_path)\n",
    "    currshape = img.shape\n",
    "    cropx, cropy = getScaledDims(currshape, ratio)\n",
    "    newimg = cropCenter(img,cropx,cropy)\n",
    "    return newimg\n",
    "\n",
    "def resizeImage(image, dims):\n",
    "    \"\"\" Resizes the image into dimensions specified by dims and converts img to 3 channels \"\"\"\n",
    "    newimg = resize(image, dims)\n",
    "    \n",
    "    # Convert from 1 channel to 3 channels\n",
    "    newimg_3d = np.empty(dims + (3,))\n",
    "    for i in range(3):\n",
    "        newimg_3d[:,:,i] = newimg\n",
    "        \n",
    "    return newimg_3d\n",
    "\n",
    "def loadTrueClass(path, number, dims):\n",
    "    \"\"\" Path: Path to .png images\n",
    "        Number: Number of images to run\n",
    "        Dims: (height, width) of the final images that will be fed into the model \"\"\"\n",
    "    \n",
    "    # Crop images to ratio specified.\n",
    "    ratio = dims[1]/float(dims[0])\n",
    "    x_True = []\n",
    "    for i, image_path in enumerate(glob.glob(path)[:number]):\n",
    "        if i % 50 == 0: print(i)\n",
    "        img = loadImage(image_path, ratio)\n",
    "    \n",
    "        # Resize all images to that dims\n",
    "        finalImg = resizeImage(img, dims)\n",
    "        x_True.append(finalImg)\n",
    "    \n",
    "    x_True = np.array(x_True)\n",
    "    \n",
    "    return x_True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load True Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirPath = '/enc_data/eddata/pacemaker'\n",
    "dataPath = os.path.join(dirPath, 'organized-data')\n",
    "pacemakerPath = os.path.join(dirPath,\"png/full_image/*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a set of patient/clipnum of images that have pacemaker\n",
    "\n",
    "pacemakerImgs = set()\n",
    "\n",
    "for image_path in glob.glob(os.path.join(dirPath,\"png/full_image/*.png\")):\n",
    "    patientid, clipnum = re.split('image\\/(\\d*)_(\\d*)-', image_path)[1:3]\n",
    "    pacemakerImgs.add((patientid, clipnum)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2145"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pacemakerImgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients: 46022\n",
      "Number of pacemaker files: 2443\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "1800\n",
      "1850\n",
      "1900\n",
      "1950\n",
      "2000\n",
      "2050\n",
      "2100\n",
      "2150\n",
      "2200\n",
      "2250\n",
      "2300\n",
      "2350\n",
      "2400\n"
     ]
    }
   ],
   "source": [
    "allPatients = os.listdir(dataPath)\n",
    "print('Number of patients: {}'.format(len(allPatients)))\n",
    "numTrueFiles = len(glob.glob(pacemakerPath))\n",
    "print('Number of pacemaker files: {}'.format(numTrueFiles))\n",
    "\n",
    "x_True = loadTrueClass(pacemakerPath, numTrueFiles, (224, 224))\n",
    "pickle.dump(x_True, open( \"x_true.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load False Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PIL(dataset):\n",
    "    \"\"\" Converts dicom dataset file to PIL files that can be imported into Keras \"\"\"\n",
    "    \n",
    "    def get_LUT_value(data, window, level):\n",
    "        \"\"\"Apply the RGB Look-Up Table for the given data and window/level value.\"\"\"\n",
    "        \n",
    "        ##### UNSURE IF I CAN DO THIS #####\n",
    "        if isinstance(window, list):\n",
    "            window = window[0]\n",
    "        if isinstance(level, list):\n",
    "            level = level[0]\n",
    "            \n",
    "        return np.piecewise(data, \n",
    "            [data <= (level - 0.5 - (window-1)/2),\n",
    "                data > (level - 0.5 + (window-1)/2)],\n",
    "                [0, 255, lambda data: ((data - (level - 0.5))/(window-1) + 0.5)*(255-0)])\n",
    "\n",
    "    image = get_LUT_value(dataset.pixel_array, dataset.WindowWidth, dataset.WindowCenter)\n",
    "    im = PIL.Image.fromarray(image).convert('L') # Convert mode to L since LUT has only 256 values: http://www.pythonware.com/library/pil/handbook/image.htm\n",
    "\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDicom(filename):\n",
    "    ds = dicom.read_file(filename)\n",
    "    img = get_PIL(ds)\n",
    "    x = img_to_array(img)/255. # Normalize to 0-1\n",
    "    return x[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients: 46022\n",
      "43875\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dirPath = '/enc_data/eddata/pacemaker'\n",
    "dataPath = os.path.join(dirPath, 'organized-data')\n",
    "allPatients = os.listdir(dataPath)\n",
    "print('Number of patients: {}'.format(len(allPatients)))\n",
    "\n",
    "with open(os.path.join(dirPath, 'regex_ann/neg.json'), 'r') as f:\n",
    "    neg = json.load(f)\n",
    "    print(len(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDicomImg(image_path, dims):\n",
    "    \"\"\" Takes path to dicom file and crops and resizes to the appropriate dimensions \"\"\"\n",
    "    img = loadDicom(filePath)\n",
    "    currshape = img.shape\n",
    "    \n",
    "    ratio = dims[1]/float(dims[0])\n",
    "    cropx, cropy = getScaledDims(currshape, ratio)\n",
    "    newimg = cropCenter(img,cropx,cropy)\n",
    "\n",
    "    finalimg = resizeImage(newimg, dims)\n",
    "    return finalimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "150\n",
      "250\n",
      "450\n",
      "750\n",
      "850\n",
      "1350\n",
      "1500\n",
      "1550\n",
      "1650\n",
      "1850\n",
      "1900\n",
      "2050\n",
      "2550\n",
      "2700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3028, 224, 224, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims = (224, 224)\n",
    "x_Neg = []\n",
    "count = 0\n",
    "\n",
    "for patient in neg:\n",
    "    if count > 3000: break\n",
    "    if count % 50 == 0: print(count)\n",
    "        \n",
    "    patientPath = os.path.join(dataPath, patient)\n",
    "    files = os.listdir(patientPath)\n",
    "    \n",
    "    for f in files:\n",
    "        if not f.endswith('.dcm'): continue\n",
    "            \n",
    "        imgPath = os.path.join(patientPath, f)\n",
    "        img = loadDicomImg(imgPath, dims)\n",
    "        x_Neg.append(img)\n",
    "        count += 1\n",
    "        \n",
    "x_Neg = np.array(x_Neg)\n",
    "x_Neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(x_Neg, open( \"x_neg.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2 (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
